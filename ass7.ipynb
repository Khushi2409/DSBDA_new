{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOc08ijCbEmxIUi+8+MVnO5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-f2-zn6nMMZr","executionInfo":{"status":"ok","timestamp":1737349625478,"user_tz":-330,"elapsed":3730,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"12f2c703-d548-4a22-faea-708d6119442f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]}]},{"cell_type":"code","source":["import nltk\n","import re\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger_eng')\n","nltk.download('punkt_tab')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sM0z7KVyMRnt","executionInfo":{"status":"ok","timestamp":1737349744780,"user_tz":-330,"elapsed":403,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"85255915-9fe2-4a82-f86a-54e08112f1bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"LeAiVVUOUQaZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text=\"MESCOW's is college of enngeeering with NAAC grade. the college has more than thousands of student\"\n","\n","from nltk.tokenize import sent_tokenize\n","tokenized_text= sent_tokenize(text)\n","print(tokenized_text)\n","\n","from nltk.tokenize import word_tokenize\n","tokenized_word=word_tokenize(text)\n","print(tokenized_word)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1l_9sR_dUNcX","executionInfo":{"status":"ok","timestamp":1737349671518,"user_tz":-330,"elapsed":368,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"2251bd50-a512-497c-f547-7c4e0e4e9945"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"MESCOW's is college of enngeeering with NAAC grade.\", 'the college has more than thousands of student']\n","['MESCOW', \"'s\", 'is', 'college', 'of', 'enngeeering', 'with', 'NAAC', 'grade', '.', 'the', 'college', 'has', 'more', 'than', 'thousands', 'of', 'student']\n"]}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","stop_words=set(stopwords.words(\"english\"))\n","print(stop_words)\n","\n","text=\"How are you ? Have you infected with HMPV\"\n","text=re.sub('[^a-zA-z]',' ',text)\n","\n","from nltk.tokenize import word_tokenize\n","tokens = word_tokenize(text.lower())\n","\n","filtered_text=[]\n","for w in tokens:\n","  if w not in stop_words:\n","    filtered_text.append(w)\n","print(\"tokened text:\", tokens)\n","print(\"filtered text:\",filtered_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFwsbes8U7ur","executionInfo":{"status":"ok","timestamp":1737349675281,"user_tz":-330,"elapsed":646,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"73c79a2c-2f41-41e8-a5d9-330172d87ad3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'we', 'what', 'to', 'most', 'or', 'more', 'i', \"should've\", 'did', 'am', 'until', 's', 'herself', 'again', 'just', \"didn't\", 'up', 'you', 'that', 'should', 'so', \"aren't\", 'ourselves', 'only', 'don', 'o', 'hasn', 'such', 'd', 'his', 'theirs', 'm', 'had', 'll', 'how', 'while', 'there', \"weren't\", 'itself', 'if', 'some', 'him', 'were', 'wouldn', 'on', 'ma', 'mightn', 'nor', 'each', 'too', 'y', 'she', 'it', 'and', 'this', 'hadn', 'which', 'shouldn', 've', 'as', 'any', 'mustn', 'where', 'won', 'by', 'once', 'be', 'hers', 'the', 'no', \"hadn't\", 'who', 'here', 'between', 'them', 'doing', 'can', 'all', 'after', 'now', 'isn', 'aren', 'yourselves', 'because', 'is', 'doesn', 'her', \"you're\", 'those', \"doesn't\", \"wasn't\", 'own', 're', 'was', \"you'd\", 'with', 'over', 'needn', 'haven', \"hasn't\", 'themselves', 'are', 'these', 'ain', 'weren', \"needn't\", 'both', 'but', 'above', \"mightn't\", 'yourself', 'didn', 'shan', \"shan't\", \"wouldn't\", 'other', 'into', 'before', \"it's\", 'then', 'during', 'he', 'same', 'through', 'few', 'very', 'their', 'will', 'in', \"that'll\", \"shouldn't\", \"don't\", 'me', 'for', 'myself', 'why', 'having', 't', 'off', 'himself', 'a', 'its', 'down', 'from', 'under', 'my', 'does', 'an', \"mustn't\", 'against', 'at', 'being', \"couldn't\", 'couldn', 'been', \"haven't\", 'your', 'do', 'below', 'yours', 'ours', 'has', 'out', 'they', \"you'll\", 'wasn', 'not', \"you've\", 'than', \"won't\", \"she's\", \"isn't\", 'have', 'further', 'of', 'about', 'when', 'whom', 'our'}\n","tokened text: ['how', 'are', 'you', 'have', 'you', 'infected', 'with', 'hmpv']\n","filtered text: ['infected', 'hmpv']\n"]}]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","e_words= [\"wait\", \"waiting\", \"waited\", \"waits\"]\n","ps =PorterStemmer()\n","for w in e_words:\n","  rootWord=ps.stem(w)\n","print(rootWord)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qVqBUR--X5Pc","executionInfo":{"status":"ok","timestamp":1737349678125,"user_tz":-330,"elapsed":381,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"f8133c53-7c51-4d15-fb43-102c3f6c9ba3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["wait\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","wnl=WordNetLemmatizer()\n","\n","text=\"wrote written fries fry\"\n","l_tokens=nltk.tokenize.word_tokenize(text)\n","print(l_tokens)\n","\n","for w in l_tokens:\n","    print(\"Lemma for {} is {}\".format(w, wnl.lemmatize(w)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlshP346ZXK1","executionInfo":{"status":"ok","timestamp":1737349933034,"user_tz":-330,"elapsed":364,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"742caf55-330a-47b7-f812-c252b2fc46bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['wrote', 'written', 'fries', 'fry']\n","Lemma for wrote is wrote\n","Lemma for written is written\n","Lemma for fries is fry\n","Lemma for fry is fry\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","data = \"All work and no play makes jack dull boy.\"\n","words = word_tokenize(data)\n","\n","\n","for word in words:\n","  print(nltk.pos_tag([word]))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzF6ipRpCYhG","executionInfo":{"status":"ok","timestamp":1737349765827,"user_tz":-330,"elapsed":366,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"089e67a3-437d-4372-b6f0-7ce70099e32d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('All', 'DT')]\n","[('work', 'NN')]\n","[('and', 'CC')]\n","[('no', 'DT')]\n","[('play', 'NN')]\n","[('makes', 'VBZ')]\n","[('jack', 'NN')]\n","[('dull', 'NN')]\n","[('boy', 'NN')]\n","[('.', '.')]\n"]}]},{"cell_type":"markdown","source":["Tf (term frequency) = occurence of word in document / total number of words\n","\n","\n","\n"],"metadata":{"id":"tpvbSAkrOi7d"}},{"cell_type":"code","source":["import pandas as pd\n","import math\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","doc= 'The car is driven on the road.'\n","\n","\n","bagOfWords = doc.split(' ')\n","\n","\n","numOfWords = dict.fromkeys(bagOfWords, 0)\n","for word in bagOfWords:\n","  numOfWords[word] += 1\n","\n","\n","def computeTf(wordDict, bagOfWord):\n","  tfDict = {}\n","  bagOfWordsCount = len(bagOfWord)\n","  for word, count in wordDict.items():\n","    tfDict[word] = count / float(bagOfWordsCount)\n","  return tfDict\n","\n","tfA = computeTf(numOfWords, bagOfWords)\n","print(tfA)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibkyG2-wHdFI","executionInfo":{"status":"ok","timestamp":1739168060714,"user_tz":-330,"elapsed":97,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"22ae6237-73e7-4a92-808c-05c91c8ca09d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'The': 0.14285714285714285, 'car': 0.14285714285714285, 'is': 0.14285714285714285, 'driven': 0.14285714285714285, 'on': 0.14285714285714285, 'the': 0.14285714285714285, 'road.': 0.14285714285714285}\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"vanBBKRMOnrw"}},{"cell_type":"code","source":["import pandas as pd\n","import math\n","\n","docA='wadia is a one of the best college in pune'\n","docB='The mescoe is near pune station'\n","\n","bagOfWordA=docA.split(' ')\n","bagOfWordB=docB.split(' ')\n","\n","uniqueWords=set(bagOfWordA).union(set(bagOfWordB))\n","\n","numOfWordsA=dict.fromkeys(uniqueWords,0)\n","for word in bagOfWordA:\n","  numOfWordsA[word] += 1\n","\n","numOfWordsB=dict.fromkeys(uniqueWords,0)\n","for word in bagOfWordB:\n","  numOfWordsB[word] += 1\n","\n","def computeTF(wordDict, bagOfWords):\n","  tfDict = {}\n","  bagOfWordsCount = len(bagOfWords)\n","  for word, count in wordDict.items():\n","    tfDict[word] = count / float(bagOfWordsCount)\n","  return tfDict\n","\n","tfA = computeTF(numOfWordsA, bagOfWordA)\n","tfB = computeTF(numOfWordsB, bagOfWordB)\n","\n","tfB"],"metadata":{"id":"Q8fiTvK0bzSw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739167608953,"user_tz":-330,"elapsed":47,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"f2a0c14b-2fb3-4a0f-fc9d-cb391aa9c7dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'is': 0.16666666666666666,\n"," 'the': 0.0,\n"," 'near': 0.16666666666666666,\n"," 'one': 0.0,\n"," 'of': 0.0,\n"," 'mescoe': 0.16666666666666666,\n"," 'wadia': 0.0,\n"," 'college': 0.0,\n"," 'station': 0.16666666666666666,\n"," 'best': 0.0,\n"," 'pune': 0.16666666666666666,\n"," 'a': 0.0,\n"," 'in': 0.0,\n"," 'The': 0.16666666666666666}"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Idf(inverse documenr frequency)=log(total number of document/ the no documnent containing the term)"],"metadata":{"id":"siEKvpWNenZA"}},{"cell_type":"code","source":["def computeIdf(documents):\n","  import math\n","  N = len(documents)\n","  idfDict = dict.fromkeys(documents[0].keys(), 0)\n","  print(idfDict)\n","  for document in documents:\n","    for word, val in document.items():\n","      if val > 0:\n","        idfDict[word] += 1\n","  for word, val in idfDict.items():\n","    idfDict[word] = math.log(N / float(val))\n","  return idfDict\n","\n","idfs = computeIdf([numOfWordsA, numOfWordsB])\n","idfs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXkbxdKwch2-","executionInfo":{"status":"ok","timestamp":1739168067048,"user_tz":-330,"elapsed":26,"user":{"displayName":"Pranjal Naphade","userId":"09804684175049216225"}},"outputId":"7dba6d82-2966-424c-fe4a-f16703845d92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'is': 0, 'the': 0, 'near': 0, 'one': 0, 'of': 0, 'mescoe': 0, 'wadia': 0, 'college': 0, 'station': 0, 'best': 0, 'pune': 0, 'a': 0, 'in': 0, 'The': 0}\n"]},{"output_type":"execute_result","data":{"text/plain":["{'is': 0.0,\n"," 'the': 0.6931471805599453,\n"," 'near': 0.6931471805599453,\n"," 'one': 0.6931471805599453,\n"," 'of': 0.6931471805599453,\n"," 'mescoe': 0.6931471805599453,\n"," 'wadia': 0.6931471805599453,\n"," 'college': 0.6931471805599453,\n"," 'station': 0.6931471805599453,\n"," 'best': 0.6931471805599453,\n"," 'pune': 0.0,\n"," 'a': 0.6931471805599453,\n"," 'in': 0.6931471805599453,\n"," 'The': 0.6931471805599453}"]},"metadata":{},"execution_count":10}]}]}